# core/adaptive_engine.py
from .models import TaskNode
from .context import GlobalContext
import logging

class AdaptiveEngine:
    """
    Acts as the system's crisis manager and recovery expert.
    When a task fails, this engine is triggered by the Orchestrator to analyze the
    failure, revert the system to a safe state, and coordinate with the PlannerAgent
    to formulate a new plan to overcome the obstacle. This component is essential for
    the system's resilience and autonomy.
    """

    def handle_failure(self, failed_task: TaskNode, context: GlobalContext) -> bool:
        """
        The core method for handling a task failure. It orchestrates the entire
        recovery process.

        The process includes:
        1.  Logging and analyzing the specific failure.
        2.  Reverting any file changes made by the failed task to ensure a clean state.
        3.  Pruning any artifacts generated by the failed task from the context.
        4.  Requesting a new, adaptive plan from the PlannerAgent.
        5.  Splicing the new recovery plan into the main TaskGraph.

        Args:
            failed_task: The TaskNode that failed.
            context: The shared GlobalContext.

        Returns:
            True if a recovery plan was successfully created and integrated,
            False otherwise, indicating a critical, unrecoverable mission failure.
        """
        logging.critical(f"ADAPTIVE ENGINE TRIGGERED for failed task: {failed_task.task_id}")

        # Step 1: Analyze the failure from the task's result.
        failure_reason = failed_task.result.message if failed_task.result else "Unknown error."
        logging.info(f"Analyzing failure reason: {failure_reason}")

        # Step 2: Revert workspace changes associated with the failed task.
        logging.info(f"Reverting workspace changes made by task '{failed_task.task_id}'.")
        context.workspace.revert_changes(task_id=failed_task.task_id)

        # Step 3: Prune artifacts created by the failed task.
        # This prevents downstream agents from using corrupted or incomplete data.
        # for key in failed_task.output_artifact_keys:
        #     context.prune_artifact(key)

        # Step 4: Request a new plan from the PlannerAgent.
        # The goal for the planner is highly specific: recover from this exact failure.
        recovery_goal = (
            f"The original plan failed at task '{failed_task.task_id}' ({failed_task.goal}) "
            f"with the error: '{failure_reason}'. "
            f"Please generate a new sub-plan to debug and resolve this issue, "
            f"then continue with the original mission."
        )

        logging.info("Invoking PlannerAgent to create a recovery plan.")
        # This would require a way to invoke the planner directly or signal the orchestrator.
        # recovery_plan = self.planner.execute(goal=recovery_goal, context=context)
        
        # if not recovery_plan.success:
        #     logging.error("Planner failed to generate a recovery plan. Mission is unrecoverable.")
        #     return False

        # Step 5: Integrate the new plan into the TaskGraph.
        # This involves marking the old failed path as 'obsolete' and adding the new nodes.
        # context.task_graph.splice_sub_graph(
        #     anchor_node_id=failed_task.task_id,
        #     sub_graph=recovery_plan.artifacts_generated[0]
        # )

        logging.info("Recovery plan successfully integrated. Mission will continue on new path.")
        return True